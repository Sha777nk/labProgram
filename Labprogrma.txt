TW-1
#load BostonHousing Data
#Machine Learning Benchmark Problems
#A collection of artificial and real-world machine learning benchmark problems,
install.packages("mlbench")
library(mlbench)
#data manipulation library
install.packages("dplyr")
library(dplyr)
#powerful graphics language for creating elegant and complex plots
install.packages("ggplot2")
install.packages("reshape2")
library(ggplot2)
#library which makes easy to transform data between wide and long formats.
library(reshape2)
data("BostonHousing")
housing <- BostonHousing
View(housing)
str(housing)

#ggplot
housing %>%
  #The infix operator %>% is not part of base R, but is in fact defined by the package magrittr (CRAN) and is heavily used by dplyr
  ggplot(aes(x = medv)) +
  stat_density() +
  labs(x = "Median Value ($1000s)", y = "Density", title = "Density Plot of Median Value House Price in Boston") +
  theme_minimal()

#summary
summary(housing$medv)

#predicted V/S original
housing %>%
  select(c(crim, rm, age, rad, tax, lstat, medv)) %>%
  melt( id.vars = "medv") %>%
  ggplot(aes(x = value, y = medv, colour = variable)) +
  geom_point(alpha = 0.7) +
  stat_smooth(aes(colour = "black")) +
  facet_wrap(~variable, scales = "free", ncol = 2) +
  labs(x = "Variable Value", y = "Median House Price ($1000s)") +
  theme_minimal()

#Set a seed of 123 and split your data into a train and test set using a 75/25 split. You may find the caret library helpful here.
install.packages("caret")
library("caret")
set.seed(123) #random number geneartion
to_train <- createDataPartition(y = housing$medv, p = 0.75, list = FALSE)
to_test<-createDataPartition(y=housing$medv, p=0.25,list=FALSE)
train <- housing[to_train, ]
test <- housing[to_test, ]

#fit a linear model
first_lm <- lm( medv ~ crim +rm +tax +lstat, data = train)

#Obtain an r-squared value for your model and examine the diagnostic plots found by plotting your linear model.
lm1_rsqu <- summary(first_lm)$r.squared
print(paste("First linear model has an r-squared value of ", round(lm1_rsqu, 3), sep = ""))
## [1] "First linear model has an r-squared value of 0.672"
#plot(first_lm)

#Fix few problems
second_lm <- lm(log(medv) ~ crim +rm + tax +lstat, data = train)

lm2_rsqu <- summary(second_lm)$r.squared
print(paste("Our second linear model has an r-squared value of ", round(lm2_rsqu, 3), sep = ""))

#One assumption of a linear model is that the mean of the residuals is zero.
abs(mean(second_lm$residuals))

#Create a data frame of your predicted values and the original values
predicted <- predict(second_lm, newdata = test)
results <- data.frame(predicted = exp(predicted), original = test$medv)

#Plot this to visualize the performance of your model.
results %>%
  ggplot(aes(x = predicted, y = original)) +
  geom_point() +
  stat_smooth() +
  labs(x = "Predicted Values", y = "Original Values", title = "Predicted vs. Original Values") +
  theme_minimal()


******************************************************************************************************************
TW-2
install.packages("KernelKnn")
data(ionosphere, package = 'KernelKnn')
apply(ionosphere, 2, function(x) length(unique(x)))

# the second column will be removed as it has a single unique value
ionosphere = ionosphere[, -2]

#Scale the data since the output depends on the distance calculations
X = scale(ionosphere[, -ncol(ionosphere)])
y = ionosphere[, ncol(ionosphere)]

# labels should be numeric and begin from 1 since classification is used
y = c(1:length(unique(y)))[ match(ionosphere$class, sort(unique(ionosphere$class))) ]

# random split in train-test and test set.
spl_train = sample(1:length(y), round(length(y) * 0.75))

#The elements of setdiff(x,y) are those elements in length(y) but not in spl_train
spl_test = setdiff(1:length(y), spl_train)
str(spl_train)
str(spl_test)


# evaluation metric
acc = function (y_true, preds) {
  
  out = table(y_true, max.col(preds, ties.method = "random"))
  
  #A key metric to start with is the overall classification accuracy. 
  #It is defined as the fraction of instances that are correctly classified.
  acc = sum(diag(out))/sum(out)
  
  acc
}

#A simple k-nearest-neighbors can be run with weights_function = NULL and the parameter 'regression' should be set to FALSE. In classification the Levels parameter takes the unique values of the response variable,
library(KernelKnn)
preds_TEST = KernelKnn(X[spl_train, ], TEST_data = X[spl_test, ], y[spl_train], k = 5 , 
                       method = 'euclidean', weights_function = NULL, regression = F,
                       Levels = unique(y))
head(preds_TEST)


#There are two ways to use a kernel in the KernelKnn function. The first option is to choose one of the existing kernels (uniform, triangular, epanechnikov, biweight, triweight, tricube, gaussian, cosine, logistic, silverman, inverse, gaussianSimple, exponential). Here, I use the canberra metric and the tricube kernel because they give optimal results
preds_TEST_tric = KernelKnn(X[spl_train, ], TEST_data = X[spl_test, ], y[spl_train], k = 10 , 
                            method = 'canberra', weights_function = 'tricube', regression = F,
                            Levels = unique(y))
head(preds_TEST_tric)


#The second option is to give a self defined kernel function. Here, I'll pick the density function of the normal distribution with mean = 0.0 and standard deviation = 1.0
norm_kernel = function(W) {
  
  W = dnorm(W, mean = 0, sd = 1.0)
  
  W = W / rowSums(W)
  
  return(W)
}
preds_TEST_norm = KernelKnn(X[spl_train, ], TEST_data = X[spl_test, ], y[spl_train], k = 10 , 
                            method = 'canberra', weights_function = norm_kernel, regression = F, 
                            Levels = unique(y))
head(preds_TEST_norm)

#I'll use the KernelKnnCV function to calculate the accuracy using 5-fold cross-validation for the previous mentioned parameter pairs,
fit_cv_pair1 = KernelKnnCV(X, y, k = 10 , folds = 5, method = 'canberra', 
                           
                           weights_function = 'tricube', regression = F, 
                           
                           Levels = unique(y), threads = 5)
str(fit_cv_pair1)
fit_cv_pair2 = KernelKnnCV(X, y, k = 9 , folds = 5,method = 'canberra',
                           
                           weights_function = 'epanechnikov', regression = F,
                           
                           Levels = unique(y), threads = 5)
str(fit_cv_pair2)



#Each cross-validated object returns a list of length 2
acc_pair1 = unlist(lapply(1:length(fit_cv_pair1$preds), 
                          
                          function(x) acc(y[fit_cv_pair1$folds[[x]]], 
                                          
                                          fit_cv_pair1$preds[[x]])))
acc_pair1
cat('accurcay for params_pair1 is :', mean(acc_pair1), '\n')
acc_pair2 = unlist(lapply(1:length(fit_cv_pair2$preds), 
                          
                          function(x) acc(y[fit_cv_pair2$folds[[x]]], 
                                          
                                          fit_cv_pair2$preds[[x]])))
acc_pair2
cat('accuracy for params_pair2 is :', mean(acc_pair2), '\n')


******************************************************************************************************************
TW-3
# Load necessary libraries
install.packages("tm")
install.packages("wordcloud")
install.packages("e1071")
library(tm)
library(wordcloud)
library(e1071)

# Load data
sms_spam_df <- read.csv("H:/6th/DSA/LAB/sms_spam.csv.csv", stringsAsFactors = FALSE)
str(sms_spam_df)

# Create and clean corpus
sms_corpus <- VCorpus(VectorSource(sms_spam_df$text))
clean_corpus <- tm_map(sms_corpus, content_transformer(tolower))
clean_corpus <- tm_map(clean_corpus, removeNumbers)
clean_corpus <- tm_map(clean_corpus, removePunctuation)
clean_corpus <- tm_map(clean_corpus, removeWords, stopwords())
clean_corpus <- tm_map(clean_corpus, stripWhitespace)

# Inspect cleaned corpus
inspect(clean_corpus[1:3])

# Create document-term matrix
sms_dtm <- DocumentTermMatrix(clean_corpus)
str(sms_dtm)

# Create wordclouds for spam and ham messages
wordcloud(clean_corpus[which(sms_spam_df$category == "ham")], min.freq = 40)
wordcloud(clean_corpus[which(sms_spam_df$category == "spam")], min.freq = 40)

# Split data into training and test sets
sms_raw_train <- sms_spam_df[1:4169,]
sms_raw_test <- sms_spam_df[4170:5559,]
sms_dtm_train <- sms_dtm[1:4169,]
sms_dtm_test <- sms_dtm[4170:5559,]
sms_corpus_train <- clean_corpus[1:4169]
sms_corpus_test <- clean_corpus[4170:5559]

# Create reduced DTM
five_times_words <- findFreqTerms(sms_dtm_train, 5)
sms_train <- DocumentTermMatrix(sms_corpus_train, control = list(dictionary = five_times_words))
sms_test <- DocumentTermMatrix(sms_corpus_test, control = list(dictionary = five_times_words))

# Convert counts to factors
convert_count <- function(x) {
  factor(ifelse(x > 0, "Yes", "No"), levels = c("No", "Yes"))
}
sms_train <- apply(sms_train, 2, convert_count)
sms_test <- apply(sms_test, 2, convert_count)

# Train Naive Bayes classifier and make predictions
sms_classifier <- naiveBayes(sms_train, factor(sms_raw_train$category))
sms_test_pred <- predict(sms_classifier, newdata = sms_test)

# Evaluate accuracy
conf_matrix <- table(sms_test_pred, sms_raw_test$category)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix) * 100
accuracy


******************************************************************************************************************
TW-4
#required packages
#install.packages("caret")
#install.packages("tidyr")

# Attach the dataset to the environment
data(iris)
# Get help on the data
help(iris)
# Rename the data
iris_dataset<-iris
# View the data
View(iris_dataset)

# View the top few rows of the data in R console
head(iris_dataset,7)

# Assigning meaningful column names
colnames(iris_dataset)<-c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
head(iris_dataset,5)

# Load the Caret package which allows us to partition the data
library(caret)
# We use the dataset to create a partition (80% training 20% testing)
index <- createDataPartition(iris_dataset$Species, p=0.80, list=FALSE)
# select 20% of the data for testing
testset <- iris_dataset[-index,]
# select 80% of data to train the models
trainset <- iris_dataset[index,]

# Dimensions of the data
dim(trainset)

# Structure of the data
str(trainset)

# Summary of the data
summary(trainset)

# Levels of the prediction column
levels(trainset$Species)

## Histogram graph
hist(trainset$Sepal.Width)

## Box plot to understand how the distribution varies by class of flower
par(mfrow=c(1,4))
for(i in 1:4) {
  boxplot(trainset[,i], main=names(trainset)[i])
}
#install.packages("ggplot2")
# begin by loading the library
library(ggplot2)
# Scatter plot
g <- ggplot(data=trainset, aes(x = Petal.Length, y = Petal.Width))
print(g)
g <-g + 
  geom_point(aes(color=Species, shape=Species)) +
  xlab("Petal Length") +
  ylab("Petal Width") +
  ggtitle("Petal Length-Width")+
  geom_smooth(method="lm")
print(g)
## Box Plot
box <- ggplot(data=trainset, aes(x=Species, y=Sepal.Length)) +
  geom_boxplot(aes(fill=Species)) + 
  ylab("Sepal Length") +
  ggtitle("Iris Boxplot") +
  stat_summary(fun.y=mean, geom="point", shape=5, size=4) 
print(box)

library(ggthemes)
## Histogram
histogram <- ggplot(data=iris, aes(x=Sepal.Width)) +
  geom_histogram(binwidth=0.2, color="black", aes(fill=Species)) + 
  xlab("Sepal Width") +  
  ylab("Frequency") + 
  ggtitle("Histogram of Sepal Width")+
  theme_economist()
print(histogram)

## Faceting: Producing multiple charts in one plot
library(ggthemes)
facet <- ggplot(data=trainset, aes(Sepal.Length, y=Sepal.Width, color=Species))+
  geom_point(aes(shape=Species), size=1.5) + 
  geom_smooth(method="lm") +
  xlab("Sepal Length") +
  ylab("Sepal Width") +
  ggtitle("Faceting") +
  theme_fivethirtyeight() +
  facet_grid(. ~ Species) # Along rows
print(facet)

